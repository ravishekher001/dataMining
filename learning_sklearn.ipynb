{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning on the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 1936 Sir Ronald Fisher wrote a paper about the iris dataset, specifically about a technique called `linear discriminant analysis` which could be used to accurately distinguish the 3 species of iris using only the `sepal` and `petal` measurements. (i.e sepal length, sepal width, petal length and petal width). In other words, Fisher framed this as a supervised learning problem, in which we are attempting to predict the species of a given iris using the four measurements. This is supervised learning because we are trying to **learn** the relationship between the 4 measurement and the outcome - which is the species of iris. If this was unlabel data, i.e if we only had the 4 measurements but not the outcome (species), then we might phrase this as unsupervised learning by attempting to cluster the samples into meaningful groups. \n",
    "\n",
    "The `iris` dataset has become a famous dataset from a machine learning perspective because it turns out to be an easy supervised learning task. There is a strong relationship between the measurements and the species and thus various machine learning models can accurately predict the species given the measurements. \n",
    "\n",
    "Goal is to predict the species of an iris using the measurements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are scikit-learn's four key requirements for working with data ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the world-famous iris dataset to learn about scikit-learn. Due to its popularity it comes bundled inside the scikit-learn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import load_iris function from datasets module\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In here, we are importing the `load_iris` function from the `sklearn.datasets` module. Note that the convention in scikit-learn is to import individual modules, classes or functions rather than importing scikit-learn as a whole. We then run the `load_iris` function to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.datasets.base.Bunch"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object is a special container called `Bunch` which is scikit-learn's special object type for storing datasets and their attributes. So `bunch` stores datasets and their attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of those attributes is called **data**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n"
     ]
    }
   ],
   "source": [
    "print(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row represents 1 flower and the 4 columns represent the four measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row is called an **observation**, some equivalent terms are sample, example, instance and record.\n",
    "\n",
    "Each column is a **feature**, some equivalent terms are predictor, attribute, independent variable, input, regressor, covariate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets print out an attribute of the iris object called `feature_names`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets print out 2 more attributes of the iris object called `target` and `target_names`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target represents what we are going to predict, which is a 0, 1 or 2 representing setosa, versicolor or verginica respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on from terminology, I would like to mention the 2 types of Supervised learning:\n",
    "* **Classification**\n",
    "* **Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for working with data in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in ML is for the model to learn the relationship between the features and the response. Our first task is make sure that the features and the response are in the form that scikit-learn expects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 key requirements to keep in mind, which are as follows:\n",
    "1. Features and response are separate objects.\n",
    "2. Features and response should be numeric\n",
    "3. Features and response should be NumPy arrays.\n",
    "4. Features and response should have specific shapes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, `iris.data` and `iris.target` fulfill this requirement, since they are stored separately. `iris.data` contains the features and `iris.target` contains the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Second requirement is that scikit-learn is only expecting to see numbers. That is both `iris.data` and `iris.target` be numeric types. This is exactly why `iris.target` is stored as 0, 1 and 2. *In scikit-learn the response object must always be numeric*. Regardless of it being a regression problem or a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Third requirement is that scikit-learn expects the features and response to be stored as NumPy arrays. NumPy has a special array called ndarray which allows us to do fast computations. In our case, the `iris.data` and `iris.target` are already stored as ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(iris.data))\n",
    "print(type(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Fourth requirement is that the feature and response objects are expected to have a certain shape. Specifically, feature objects should have 2-Dimensions in which the first-dimension (represented by rows) is the number of observations and the second-dimension (represented by columns) is the number of features. All NumPy arrays have a shape attribute so that we can verify the shape of iris.data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(iris.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response object is expected to have single dimension and that single dimension should have the same magnitude as the first dimension of the feature object (i.e number of observations). In other words, there must be 1 response corresponding to each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have now verified that iris.data and iris.target conform to the 4 scikit-learn requirements for feature and response objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The scikit-learn convention is for the feature data to be stored in an object named X and for the response data to be stored in an object named Y. Thus, we will store iris.data in X and iris.target in Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store feature matrix in X\n",
    "X = iris.data\n",
    "\n",
    "# store response vector in y\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that X is capitalized since it represents a matrix whereas y is lowercase since it represents a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn 4-step modeling pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually begin the machine learning process. scikit-learn provides a uniform interface for machine learning models and thus there is common pattern which can be re-used across models. The first step in this pattern is to import the relevant class. In this case we import `knearestclassifier` from `sklearn.neighbors` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import the class you plan to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn is carefully organized into modules such as neighbors so that it is easy to find the class you are looking for. The second step in the pattern is to instantiate the `estimator` . Scikit-learn calls models as estimators because their primary role is to estimate unknown quantities. This process is called `instantiation` because we are creating an instance of the k-nearest classifier class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** \"Instantiate\" the \"estimator\"\n",
    "* \"Estimator\" is scikit-learn's term for model\n",
    "* \"instantiate\" means \"make an instance of\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now created an instance of the KNeighborsClassifier class and called it `knn`. In other words we now have an object called `knn` that knows how to do K-nearest neighbor classification and **it is just waiting for us to give it some data**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, there are 2 important points about instantiating the estimator:\n",
    "1. You can specify tuning parameters (aka \"hyperparameters\") during this step.\n",
    "2. All parameters not specified are set to their defautls. By printing the knn object, we can see the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets move on to the 3rd step which is to fit model with data (aka \"model training\"). This is the model training step, in which the model *learns* the relationship between the features and the response. The underlying mathematical process through which this learning occurs varies by model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Fit the model with data (aka \"model training\")\n",
    "* Model is learning the relationship between X and y\n",
    "* Occurs in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation occurs in-place, so I don't need to assign it to another object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 4th and final step is to make predictions for new observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Predict the response for a new observation\n",
    "* New observations are called \"out-of-sample\" data\n",
    "* Uses the information it learned during the model training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, I am inputing the measurements for an unknown `iris` and asking the fitted model to predict the iris species based on what it has learned in the previous step. I use the `predict` method on the knn object and pass it the features of the unknown iris as a python list. It is expecting a numpy array but it still works with a list since numpy automatically converts it to an array of the appropriate shape. For example see the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Shravan/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict([3, 5, 4, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Unlike the fit method, the predict method does return a value. It returns a numpy array with the predicted response values. In this case, the k-nearest neighbors algorithm using k = 1, predicts a response value of '2'. \n",
    "\n",
    "Scikit-learn does not know what this '2' means so we need to keep track of the encoding that 2 means verginica. And thus verginica is the predicted species for the unknown iris with measurements: [3, 5, 4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = [[3, 4, 5, 2], [5, 4, 3, 2]]\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using a different value for K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you wanted to try a different value for K, lets say 5. This is known as model tuning in which you are varying the arguments that you pass to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model (using the value K=5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit the model with data\n",
    "knn.fit(X, y)\n",
    "\n",
    "# predict the response for new observations\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a different classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing I love about scikit-learn, is that its models have a consistent interface. Which means that I can use the same 4-step pattern on a different model with relative ease. For example, I might try logistic regression which despite its name is another model used for classification. I simply import `LogisticRegression` from the `linear_model` module. Then instantiate the model with default parameters, fit the model with data, and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# predict the response for new observations\n",
    "logreg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the model predicts a 2 for the first unknown iris and a 0 for the second unknown iris. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you must be wondering, which model produced the correct predictions ? The answer is that we don't know because these are out-of-sample observations meaning that we don't know the true response values. As we talked earlier, our goal in supervised learning is to build models that generalize on new data. However, we often aren't able to truly measure how well our models will perform on out-of-sample data. Does that mean that we are forced to guess how well our models are likely to do ? Thankfully no. In the next section, we begin to evaluate the model evaluation procedures which allow us to estimate how well our models are likely to perform on out-of-sample data using our existing labelled data. These procedures will help us to choose which value of K is best for KNN and whether to choose KNN or logistic regression is a better choice for our particular task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I choose which model to use for my supervised learning task ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classification task was to predict the species of an unknown iris. We tried using three classification models:\n",
    "* KNN (K=1)\n",
    "* KNN (K=5)\n",
    "* Logistic Regression\n",
    "\n",
    "We recieved 3 different sets of predictions. Because this is out-of-sample data, we don't know the true response values and thus we can't actually say which model made the best predictions. However, we still need to choose between these 3 models. The goal of supervised learning is to build a model that generalizes to out-of-sample data, that is, what we really need is a procedure that allows us to estimate how well a given model is likely to perform on out-of-sample data. This is known as a model evaluation procedure. If we can estimate the likely performance of our 3 models,  then we can use that performance estimate to **choose** between the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first procedure is widely known but it does not have an official name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Procedure #1: Train and test on the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is simple we train our model on the entire dataset, and we test our model by checking how well it performs on that same data. This appears to solve our original problem - which was that we made some predictions but we couldn't check whether those predictions were correct. By testing our model, on a dataset for which we do actually know the response values we can check how well our model is doing by comparing the predicted response values with the true response values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris dataset is already loaded and we have our `feature` matrix in X and our `response` vector in y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# predict the response for observations in X\n",
    "y_pred = logreg.predict(X)\n",
    "\n",
    "# Check how many predictions were generted\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a numerical way to evaluate how well our model performed. The most obvious choice would be `Classification Accuracy` which is the proportion of correct predictions. This is known as our evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can think of 3 different ways of doing this, but I am going to show you the one way I recommend which is to use the `metrics` module of scikit-learn. \n",
    "* First we import the metrics module\n",
    "* Second we invoke the `accuracy_score` **function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95999999999999996"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the classification accuracy for our logistic regression model\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means, it compared the 150 true responses with the corresponding 150 predicted responses and calculated that 96% of our predictions were correct. This is known as our training accuracy because we are testing the model on the same data that we used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X)\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification accuracy is slightly better than Logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN(K=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X)\n",
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification accuracy is 100% it performed even better than the other 2 models, and so we would conclude KNN with K=1 is the best model to use with this data. OR NOT! Think about that for a second. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation procedure #2: Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "## print the shapes of X and y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the data into training and testing sets, we are going to use scikit-learn's built-in, `train_test_split` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Shravan/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(60, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90,)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 2: train the model on the training set\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916666666667\n"
     ]
    }
   ],
   "source": [
    "# Compute the prediction accuracy\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this model, achieved a testing accuracy of 0.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cross-validation example: parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now go through an example where cross-validation can be used in scikit-learn to help us with parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Select the best tuning parameters (aka \"hyperparameters\") for KNN on the iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, we want to choose the tuning parameters for KNN which will produce a model that best generalizes the out-of-sample data. We will focus on tuning the `k` in K-NearestNeighbors which represents the number of nearest neighbors that are taken into account when making a prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our primary **function** for cross-validation in scikit-learn will be `cross_val_score` which we will import from ` sklearn.cross_validation ` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to try out a value of k=5, so we instantiate a KNeighborsClassfier model with n_neighbors = 5 and save the model as an object called knn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the `cross_val_score` function, giving this function 5 parameters:\n",
    "* **first parameter**: model object - knn\n",
    "* **second parameter**: X - our feature matrix, it is very important to note that we are passing the entirety of X and y to cross_val_score and *NOT* X_train or y_train. cross_val_score takes care of splitting the data into folds and thus we do not need to split the data ourselves using train_test_split function.\n",
    "* **third parameter**: y - our response vector\n",
    "* **fourth parameter**: cv - 10 fold cross validation. \n",
    "* **fifth parameter**: scoring='accuracy' - which means we want to use classification accuracy as the evaluation metric. There are many possible evaluation metrics so it is always better to specify which one we want to use. You can see the complete list of evaluation metrics in scikit-learns model evaluation documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss what the `cross_val_score` function actually does and what it returns. Basically, the `cross_val_score` runs the first 4 steps of k-fold cross validation. That is:\n",
    "1. Split the dataset into K **equal** paritions (or \"folds\").\n",
    "2. Use fold 1 as the **testing set** and the union of the other folds as the **training set**.\n",
    "3. Calculate **testing accuracy**.\n",
    "4. Repeat steps 2 and 3 K-times, using a **different fold** as the testing set each time.\n",
    "5. Use the **average testing accracy** as the estimate of out-of-sample accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will split X and y into 10 equal folds, it will train the KNN model on the folds 2-thru-10, it will test the model on fold 1, and calculate the testing accuracy. Then it will train the KNN model on the fold 1 and 3-thru-10 and test the model on fold 2 and calculate the testing accuracy. It will do that 8 more times. \n",
    "\n",
    "When it is finished, it will return the **10 accuracy scores** as a NumPy array.\n",
    "\n",
    "In our code, we will save that NumPy array as an object `scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.93333333  1.          1.          0.86666667  0.93333333\n",
      "  0.93333333  1.          1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see that during the first iteration, the model achieved an accuracy of 100%\n",
    "- In the second iteration, the model achieved an accuracy of 93.3%\n",
    "\n",
    "As mentioned above, we will average the 10 scores and use that as our out-of-sample accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It happens that NumPy arrays have a method called `mean` . So we can simply call the mean to see the `mean accuracy score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It turns out to be about 97%. Because we used cross-validation and arrived at this result, we are more confident that it is an accurate estimate of out-of-sample accuracy than we would be if we had used train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUR goal here is to find the optimal value of K for KNN which we set using the n_neighbors parameter. Thus we will loop through a range of reasonable values for K and for each value use 10-fold cross-validation to estimate the out-of-sample accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95999999999999996, 0.95333333333333337, 0.96666666666666656, 0.96666666666666656, 0.96666666666666679, 0.96666666666666679, 0.96666666666666679, 0.96666666666666679, 0.97333333333333338, 0.96666666666666679, 0.96666666666666679, 0.97333333333333338, 0.98000000000000009, 0.97333333333333338, 0.97333333333333338, 0.97333333333333338, 0.97333333333333338, 0.98000000000000009, 0.97333333333333338, 0.98000000000000009, 0.96666666666666656, 0.96666666666666656, 0.97333333333333338, 0.95999999999999996, 0.96666666666666656, 0.95999999999999996, 0.96666666666666656, 0.95333333333333337, 0.95333333333333337, 0.95333333333333337]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "k_range = range(1, 31)\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10fbcc2e8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAokxxpiK/F93pGKkN6h/eQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ed3e438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of the bias-variance trade-off in which low values of K procude a model with low bias and high variance and high values of K produce a model with high bias and low variance. The best model is found in the middle because it appropriately balances bias and variance **and thus it is most likely to generalize to out-of-sample data**. When deciding what exact value of K is the best, it is generally recommended to choose the value of K with the simplest model. In the case of KNN, higher values of K produce lower complexity models and thus we will chose K=20 as our single best KNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have used Cross-Validation to help us in parameter tuning, now lets take a look at an example of how cross-validation can be used to choose between different types of models: **KNN(k=20) vs LogisticRegression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation example: model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Compare the best KNN model with logistic regression on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with the best KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "print(cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953333333333\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print(cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can conclude that KNN with k=20 is a better choice than logistic regression for this particular task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets see how Cross-Validation can help with feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation example: feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:**: Select whether the Newspaper feature shoul be included in the linear regression model on the advertising dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the advertising dataset\n",
    "data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a python list of three feature names\n",
    "feature_cols = ['TV', 'radio', 'newspaper']\n",
    "\n",
    "# use the list to select a subset of the DataFrame (X)\n",
    "X = data[feature_cols]\n",
    "\n",
    "# select the sales column as the response (y)\n",
    "y = data.sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.56038438 -3.29767522 -2.08943356 -2.82474283 -1.3027754  -1.74163618\n",
      " -8.17338214 -2.11409746 -3.04273109 -2.45281793]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Shravan/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py:90: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/Shravan/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py:90: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/Shravan/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py:90: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/Shravan/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py:90: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/Shravan/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py:90: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/Shravan/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py:90: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/Shravan/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py:90: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/Shravan/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py:90: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/Shravan/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py:90: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/Users/Shravan/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py:90: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with all three features\n",
    "lm = LinearRegression()\n",
    "scores = cross_val_score(lm, X, y, cv=10, scoring='mean_squared_error')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.56038438 -3.29767522 -2.08943356 -2.82474283 -1.3027754  -1.74163618\n",
      " -8.17338214 -2.11409746 -3.04273109 -2.45281793]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with all three features\n",
    "lm = LinearRegression()\n",
    "scores = cross_val_score(lm, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.56038438  3.29767522  2.08943356  2.82474283  1.3027754   1.74163618\n",
      "  8.17338214  2.11409746  3.04273109  2.45281793]\n"
     ]
    }
   ],
   "source": [
    "# fix the sign of MSE\n",
    "mse_scores = -scores\n",
    "print(mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.69135317081\n"
     ]
    }
   ],
   "source": [
    "# convert MSE to RMSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "print(rmse_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.67967484191\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross validation with two features (excluding newspapers)\n",
    "feature_cols = ['TV', 'radio']\n",
    "X = data[feature_cols]\n",
    "print(np.sqrt(-cross_val_score(lm, X, y, cv=10, scoring='neg_mean_squared_error')).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since RMSE is less than the model with newspaper and since our goal is to minimize the RMSE, we would conclude that removing the Newspaper from the model yields more accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of parameter tuning using `cross_val_score`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Select the best tuning parameters (aka \"hyperparameters\") for KNN on the iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few sections above we saw how we can use the `cross_val_score` function to find the best tuning parameters for KNN. There we had to write our own code and draw a plot of **Cross-validated accuracy** vs **Value of K for KNN** and then visually access which K value is the best. This is something we do often and it appears that there could be an easier way to do this. And yes, there is **GridSearchCV** which was created for that purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More efficient parameter tuning using `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV** allows you to define a set of parameters that you want to try with a given model and it will automatically run cross-validation using each of those parameters keeping track of the resulting scores. Essentially it replaces the `for loop` above as well as providing some additional functionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started with GridSearchCV we first import the class from `sklearn.grid_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly like above, we create a python list called `k_range` that specifies the k-values that we would like to search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "k_range = range(1, 31)\n",
    "print(list(k_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create what is known as a `parameter grid`. It is simply a python dictionary, in which the key is the parameter name, and the value is a list of values that should be searched for that parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]}\n"
     ]
    }
   ],
   "source": [
    "# create a parameter grid: map the parameter names to the values that should be searched.\n",
    "param_grid = dict(n_neighbors=list(k_range))\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this dictionary has a single key-value pair, in which the key is the string `n_neighbors` and the value is a list of numbers from 1 thru 30. Next we will instantiate the grid. You will notice that it has the same parameters as `cross_val_score` except it does not have the X and y but it does include the `param_grid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the grid\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of the `grid` object as follows: \n",
    "* it is an object ready to do a 10-fold cross-validation on a KNN model using classification accuracy as the evaluation metric. But in addition it is given this parameter grid, so that it knows that it has to repeat the 10-fold cross-validation process 30 times and each time the n_neigbhor's parameter should be given a different value from the list. Hopefully this helps you to understand why the parameter_grid is specified using key-value pairs. We can't just give the GridSearchCV a list of numbers 1 thru 30, because it won't know what to do with those numbers. Instead we need to specifiy which model parameter, in this case, n_neighbors, should take on values 1 thru 30. One final note about instantiating the grid. If you computer supports parallel processing you can set the n_jobs parameter to -1 to instruct scikit-learn to use all available processors. Finally we **fit** the grid with data, with just the X and y objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store feature matrix in X\n",
    "X = iris.data\n",
    "\n",
    "# store response vector in y\n",
    "y = iris.target\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step may take a while depending on the model and the data and the number of parameters being searched. Remember that this is running 10-fold cross-validation 30 times and thus the KNN model is being fit and predictions being made 300 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that grid search is done, let's take a look at the results which are stored in the `grid_scores_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.96000, std: 0.05333, params: {'n_neighbors': 1},\n",
       " mean: 0.95333, std: 0.05207, params: {'n_neighbors': 2},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 3},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 4},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 5},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 6},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 7},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 8},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 9},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 10},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 11},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 12},\n",
       " mean: 0.98000, std: 0.03055, params: {'n_neighbors': 13},\n",
       " mean: 0.97333, std: 0.04422, params: {'n_neighbors': 14},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 15},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 16},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 17},\n",
       " mean: 0.98000, std: 0.03055, params: {'n_neighbors': 18},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 19},\n",
       " mean: 0.98000, std: 0.03055, params: {'n_neighbors': 20},\n",
       " mean: 0.96667, std: 0.03333, params: {'n_neighbors': 21},\n",
       " mean: 0.96667, std: 0.03333, params: {'n_neighbors': 22},\n",
       " mean: 0.97333, std: 0.03266, params: {'n_neighbors': 23},\n",
       " mean: 0.96000, std: 0.04422, params: {'n_neighbors': 24},\n",
       " mean: 0.96667, std: 0.03333, params: {'n_neighbors': 25},\n",
       " mean: 0.96000, std: 0.04422, params: {'n_neighbors': 26},\n",
       " mean: 0.96667, std: 0.04472, params: {'n_neighbors': 27},\n",
       " mean: 0.95333, std: 0.04269, params: {'n_neighbors': 28},\n",
       " mean: 0.95333, std: 0.04269, params: {'n_neighbors': 29},\n",
       " mean: 0.95333, std: 0.04269, params: {'n_neighbors': 30}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the complete results (list of named tuples)\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is actually a list of 30 named tuples. The 1st tuple indicates that when the n_neighbors parameter was set to 1, the mean cross-validated accuracy was 0.96 and the standard deviation of the accuracy scores was 0.053. While the mean is usually what we pay attention, the standard deviation is something to keep in mind, because if the standard deviation is, then that means the cross-validated accuracy might not be as reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, you can see that there is 1 tuple for each of the 30 trials of cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will examine the individual tuples, just in case you need to do so in the future. I am going to slice the list to select the first tuple using the [0] notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.96000, std: 0.05333, params: {'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "# examine the first tuple\n",
    "print(grid.grid_scores_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it is a named tuple, I can select its elements using the dot notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n",
      "[ 1.          0.93333333  1.          0.93333333  0.86666667  1.\n",
      "  0.86666667  1.          1.          1.        ]\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "# examine the first tuple\n",
    "print(grid.grid_scores_[0].parameters)\n",
    "print(grid.grid_scores_[0].cv_validation_scores)\n",
    "print(grid.grid_scores_[0].mean_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parameters is simply a dictionary of the parameters that were used.\n",
    "* cv_validation_scores is an array of the 10 accuracy scores that were generated during 10-fold cross-validation using that parameter.\n",
    "* mean_validation_score is the mean of the 10 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to collect the `mean_validation_scores` accross the 30 runs and plot them like we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96, 0.9533333333333334, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9733333333333334, 0.9666666666666667, 0.9666666666666667, 0.9733333333333334, 0.98, 0.9733333333333334, 0.9733333333333334, 0.9733333333333334, 0.9733333333333334, 0.98, 0.9733333333333334, 0.98, 0.9666666666666667, 0.9666666666666667, 0.9733333333333334, 0.96, 0.9666666666666667, 0.96, 0.9666666666666667, 0.9533333333333334, 0.9533333333333334, 0.9533333333333334]\n"
     ]
    }
   ],
   "source": [
    "# create a list of the mean scores only\n",
    "grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]\n",
    "print(grid_mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x112c4cb00>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAokxxpiK/F93pGKkN6h/eQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112c73908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "plt.plot(k_range, grid_mean_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the plot is identical to the one we generated above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now you might be thinking that writing a list comprehension and then making a plot can't possibly be the most efficient way to view the results of GridSearch, you are exactly right. Once a grid is fit with data it exposes 3 attributes which are quite useful:\n",
    "1. best_score_ : is the single best score achieved across all of the parameters\n",
    "2. best_params_: is a dictionary of the parameters used to generate that score.\n",
    "3. best_estimator_ : is the actual model object fit with those parameters which conviniently shows you all of the default parameters for that model that you did not specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "{'n_neighbors': 13}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=13, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# examine the model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have noticed in the plot, there are 2 more k values that produced a score of 0.98. I don't know for sure why GridSearch chose 13 as the best value but probably it picks the first occurance of the highest score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching multiple parameters simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's pretend that you are using a `DecisionTreeClassifier` which is a model we haven't yet covered in the series. Two important tuning parameters are `max_depth` and `min_samples_leaf` you can tune those parameters independently meaning that you used different values for `max_depth` while leaving `min_samples_leaf` at its default value and then you try different values for `min_samples_leaf` while leaving `max_depth` at its default value. The problem with that approach is that the best model performance can be achieved when neither of those 2 values are at their default values. Thus you need to **search** those two parameters simultaneously which is exactly what we are about to do with *GridSearchCV*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of KNN, another parameter which might be worth tuning other than K is the weights parameter. This weights parameter controls how the K-nearest neighbors are weighted when making a prediction. The default option is **uniform** which means that all points in the neighborhood weighted equally but another option is **distance** which weights closer neighbors more heavily than further neighbors. Thus, I am going to create a list of those options called weight_options in addition to the 30 integer options represented by k_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
